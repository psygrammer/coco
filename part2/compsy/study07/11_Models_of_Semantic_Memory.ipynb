{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Models of Semantic Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 / 인지모델링 : 파트2 [1]\n",
    "* 김무성    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contetns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Introduction\n",
    "* Classic Models and Themes in Semantic Memory Research\n",
    "* Connectionist Models of Semantic Memory\n",
    "    - \n",
    "Rumelhart Networks\n",
    "    - Dynamic Attractor Networks\n",
    "* Distributional Models of Semantic Memory\n",
    "    - Latent Semantic Analysis\n",
    "    - Moving Window Models\n",
    "    - Random Vector Models\n",
    "    - Probabilistic Topic Models\n",
    "    - Retrieval-Based Semantics\n",
    "* Grounding Semantic Models\n",
    "* Compositional Semantics\n",
    "* Common Lessons and Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* semantic memory\n",
    "* semantic space model\n",
    "* distributional semantics\n",
    "* connectionist network\n",
    "* concepts\n",
    "* cognitive model\n",
    "* latent semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Meaning is simultaneously the most obvious feature of memory—we can all compute it rapidly and automatically—and the most mysterious aspect to study.\n",
    "* Semantic memory is necessary for us to construct meaning from otherwise meaningless words and utterances, to recognize objects, and to interact with the world in a knowledge-based manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Semantic memory typically refers to memory for word meanings, facts, concepts, and general world knowledge.\n",
    "    - concept\n",
    "    - proposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goal of this chapter is to provide an overview of recent advances in models of semantic memory.\n",
    "* Although there are several exciting new developments in verbal conceptual theory (e.g., Louwerse’s (2011) Symbol Interdependency Hypothesis), we focus exclusively on models that are \n",
    "    - explicitly expressed by computer code or\n",
    "    - mathematical expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We opt here to follow two major clusters of cognitive models that have been prominent: \n",
    "    - distributional models \n",
    "        - models that specify how concepts are learned from statistical experience (distributional models)\n",
    "    - connectionist models\n",
    "        - models that specify how propositions are learned or that use conceptual representations in cognitive processes (connection- ist models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Models and Themes in Semantic Memory Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The three classic models of semantic memory most commonly discussed are\n",
    "    - semantic networks\n",
    "    - feature-list models\n",
    "    - and spatial models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### semantic networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The semantic network has traditionally been one of the most common theoretical frameworks used to understand the structure of semantic memory.\n",
    "    - Collins and Quillian (1969) originally proposed a hierarchical model of semantic memory in which concepts were nodes and propositions were labeled links\n",
    "        - e.g., the nodes for dog and animal were connected via an “isa” link\n",
    "    - The superordinate and subordinate structure of the links produced a hierarchical tree structure\n",
    "        - animals were divided into birds, fish, etc., and birds were further divided into robin, sparrow, etc.\n",
    "    - A later version of the semantic network model proposed by Collins and Loftus (1975) deemphasized the hierarchical nature of the network in favor of the process of spreading activation through all network links simultaneously to account for semantic priming phenomena—in particular, the ability to produce fast negative responses.\n",
    "* Early semantic networks can be seen as clear predecessors to several modern connectionist models, and features of them can also be seen in modern probabilistic and graphical models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature-list models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A competing model was the feature-comparison model of Rips, Shoben, and Smith (1973). \n",
    "    - In this model, a word’s meaning is encoded as a list of binary descriptive features, which were heavily tied to the word’s perceptual referent.\n",
    "    - For example, the <has_wings> feature would be turned on for a robin, but off for a beagle.\n",
    "    - Smith, Shoben, and Rips (1974) proposed two types of semantic features: \n",
    "        - defining features that all concepts have, and\n",
    "        - characteristic features that are typical of the concept, but are not present in all cases.\n",
    "        - For example, all birds have wings, but not all birds fly.\n",
    "* Modern versions of feature-list models use aggregate data collected from human raters in property generation tasks (e.g., McRae, de Sa, & Seidenberg, 1997)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spatial models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A third type was the spatial model, which emer- ged from Osgood’s (1952, 1971) early attempts to empirically derive semantic features using semantic differential ratings.\n",
    "    - Osgood had humans rate words on a Likert scale against a set of polar opposites (e.g., rough-smooth, heavy-light), and a word’s meaning was then computed as a coordinate in a multidimensional semantic space.\n",
    "* Early spatial models can be seen as predecessors of modern semantic space models of distributional semantics (but co-occurrences in text corpora are used as the data on which the space is constructed rather than human ratings).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectionist Models of Semantic Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rumelhart Networks\n",
    "* Dynamic Attractor Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumelhart Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Attractor Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional Models of Semantic Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Latent Semantic Analysis\n",
    "* Moving Window Models\n",
    "* Random Vector Models\n",
    "* Probabilistic Topic Models\n",
    "* Retrieval-Based Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Window Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Vector Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“A dog bit the mailman,” the memory representation for dog is updated as mdog = ebit + emailman. In the same sentence, mbit = edog + emailman and mmailman = edog + ebit are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Based Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounding Semantic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compositional Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Lessons and Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] The Oxford Handbook of Computational and Mathematical Psychology - http://www.amazon.com/Handbook-Computational-Mathematical-Psychology-Library/dp/0199957991\n",
    "* [2] Memory - https://docs.google.com/viewer?url=http%3A%2F%2Fwww.appsychology.com%2FappsychPP%2Fappsychology%2FAPPsychNewPP%2FMemory%2FMemory.ppt\n",
    "* [3] Long Term Memory - https://docs.google.com/viewer?url=http%3A%2F%2Fcogsci.ucd.ie%2Fcourses%2FCogPsych%2FCogPsychLecture_3.ppt\n",
    "* [4] Semantic Memory - https://docs.google.com/viewer?url=https%3A%2F%2Fus.sagepub.com%2Fsites%2Fdefault%2Ffiles%2Fupm-binaries%2F13843_Lecture__Chapter_8.ppt\n",
    "* [5] Semantic Memory - https://docs.google.com/viewer?url=http%3A%2F%2Fpsychology.illinoisstate.edu%2Fjccutti%2Fpsych368%2Flectures%2F17.memory12.ppt\n",
    "* [6] Models of Episodic Memory - https://drive.google.com/drive/folders/0B-Cmo_VNw8YnRTNDZmNDMEJTaEk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
