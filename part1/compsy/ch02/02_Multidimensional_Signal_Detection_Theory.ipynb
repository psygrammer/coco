{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Multidimensional Signal Detection Theory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 인지모델링 스터디 교재 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Abstract\n",
    "* Introduction\n",
    "* General Recognition Theory\n",
    "* The Multivariate Normal Model\n",
    "* Applying GRT to Data\n",
    "* Fitting the GRT Model to Identification Data\n",
    "* The Summary Statistics Approach\n",
    "* An Empirical Example\n",
    "* Extensions to Response Time\n",
    "* The RT-Distance Hypothesis\n",
    "* Process Models of RT\n",
    "* Neural Implementations of GRT\n",
    "* Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multidimensional signal detection theory\n",
    "    - <font color=\"red\">multivariate extension</font> of signal detection theory\n",
    "* two fundamental assumptions,\n",
    "    - every <font color=\"red\">mental state is noisy</font> \n",
    "    - every <font color=\"red\">action requires a decision</font>\n",
    "* The most widely studied version is known as <font color=\"red\">general recognition theory (GRT)</font>. \n",
    "    - General recognition theory assumes\n",
    "        - the <font color=\"red\">percept on each trial</font> can be <font color=\"red\">modeled as a random sample</font> from a <font color=\"red\">multivariate probability distribution</font> defined over the <font color=\"red\">perceptual space</font>.\n",
    "        - <font color=\"red\">Decision bounds divide</font> this space into <font color=\"red\">regions</font> that are each <font color=\"red\">associated with a response alternative</font>. \n",
    "* General recognition theory rigorously defines and tests \n",
    "    - a number of important <font color=\"red\">perceptual and cognitive conditions</font>, \n",
    "    - including <font color=\"red\">perceptual and decisional separability</font> \n",
    "    - and <font color=\"red\">perceptual independence</font>. \n",
    "* General recognition theory has been used to analyze data from identification experiments in two ways: \n",
    "    - (1) <font color=\"red\">fitting and comparing models</font> that make different assumptions about perceptual and decisional processing, \n",
    "    - (2) <font color=\"red\">testing assumptions</font> by computing summary statistics and checking whether these satisfy certain conditions. \n",
    "* Much has been learned recently about the neural networks that mediate the perceptual and decisional processing modeled by GRT, and this knowledge can be used to improve the design of experiments where a GRT analysis is anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* signal detection theory\n",
    "* general recognition theory\n",
    "* perceptual separability\n",
    "* perceptual independence\n",
    "* identification\n",
    "* categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal detection theory(신호탐지이론) ? [2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://ko.wikipedia.org/wiki/%EC%8B%A0%ED%98%B8%ED%83%90%EC%A7%80%EC%9D%B4%EB%A1%A0\n",
    "* http://en.wikipedia.org/wiki/Detection_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/6/65/SignalDetection.png/600px-SignalDetection.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|         |         반응 \"없음\"            |        반응 \"있음\"\n",
    "| --------| ---------------------------- | -----------------------------\n",
    "| 신호 있음 | <font color=\"red\">누락</font>  |            적중\n",
    "| 신호 없음 |\t       정기각                | <font color=\"red\">오경보</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                  |          Respond  \"Absent\"           |        Respond \"Present\"\n",
    "| -----------------| ------------------------------------ | ------------------------------------\n",
    "| Stimulus Present |\t <font color=\"red\"> Miss</font>   |\t                 Hit\n",
    "| Stimulus Absent  |             Correct Rejection        |\t<font color=\"red\">False Alarm</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one sensory dimension signal detection theory \n",
    "* -> Multidimensional signal detection theory \n",
    "* -> (The most widely studied version of multidimensional signal detection theory is known as) general recognition theory\n",
    "    - First, with more than one dimension, it becomes necessary to model <font color=\"red\">interactions (or the lack thereof) among those dimensions</font>.\n",
    "    - Second, the problem of how to model decision processes when the perceptual space is multidimensional is <font color=\"red\">far more difficult than</font> when there is only one sensory dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# General Recognition Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As an example, \n",
    "\n",
    "* consider an experiment in which participants are asked to <font color=\"red\">categorize or identify faces</font> that vary across trials on <font color=\"red\">gender and age</font>.\n",
    "* Suppose there are <font color=\"red\">four stimuli (i.e., faces)</font> that are created by factorially <font color=\"red\">combining two levels of each dimension</font>. \n",
    "* In this case we could denote \n",
    "    - the <font color=\"red\">two levels of the gender dimension</font> by \n",
    "        - A1 (male) and\n",
    "        - A2 (female) \n",
    "    - and the <font color=\"red\">two levels of the age dimension</font> by \n",
    "        - B1 (teen) and\n",
    "        - B2 (adult). \n",
    "* Then the four faces are denoted as \n",
    "    - A1B1 (male teen), \n",
    "    - A1B2 (male adult), \n",
    "    - A2B1 (female teen), and \n",
    "    - A2B2 (female adult)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with signal detection theory, a fundamental assumption of GRT is that <font color=\"red\">all perceptual systems are inherently noisy</font>. There is noise both in the <font color=\"red\">stimulus</font> (e.g., photon noise) and in the <font color=\"red\">neural systems</font> that determine its sensory representation (Ashby & Lee, 1993). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.1-1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.1-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perceptual separability\n",
    "#### perceptual independence\n",
    "#### decisional separability\n",
    "\n",
    "* In GRT, the <font color=\"red\">relationship of the joint pdf to the marginal pdfs plays a critical role</font> in determining whether the stimulus dimensions are <font color=\"red\">perceptually integral</font> or <font color=\"red\">separable</font>.\n",
    "* Component A is <font color=\"red\">perceptually separable</font> from component B if the <font color=\"red\">subject’s perception of A does not change when the level of B is varied</font>.\n",
    "    - For example, age is perceptually separable from gender if the perceived age of the adult in our face experiment is the same for the male adult as for the female adult, and if a similar invariance holds for the perceived age of the teen.\n",
    "*  If perceptual separability fails then A and B are said to be <font color=\"red\">perceptually integral</font>.\n",
    "* Another purely perceptual phenomenon is <font color=\"red\">perceptual independence</font>.\n",
    "    - According to GRT, components A and B are perceived independently in stimulus AiBj if and only if the perceptual value of component A is statistically independent of the perceptual value of component B on AiBj trials.\n",
    "* Note that perceptual independence is a property of a single stimulus, whereas perceptual separability is a property of groups of stimuli.\n",
    "* A third important construct from GRT is decisional separability.\n",
    "    - In our hypothetical experiment with stimuli A1B1, A1B2, A2B1, and A2 B2, and two perceptual dimensions X1 and X 2, decisional separability holds on dimension X 1 (for example),\n",
    "    - if the subject’s decision about whether stimulus component A is at level 1 or 2 depends only on the perceived value on dimension X 1. \n",
    "    - A decision bound is a line or curve that separates regions of the perceptual space that elicit different responses. \n",
    "    - The only types of decision bounds that satisfy decisional separability are vertical and horizontal lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A is perceptually separable from B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B is perceptually separable from A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A and B are perceived independently in stimulus AiBj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Multivariate Normal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far we have made <font color=\"red\">no assumptions about the form of the joint or marginal pdfs</font>. \n",
    "* Our <font color=\"red\">only assumption</font> has been that there exists some <font color=\"red\">probability distribution associated with each stimulus</font> and that these distributions are all embedded in some Euclidean space\n",
    "    - <font color=\"red\">the percepts are multivariate normally distributed</font>.\n",
    "    - The multivariate normal distribution includes two assumptions.\n",
    "        - First, the <font color=\"red\">marginal distributions are all normal</font>.\n",
    "        - Second, the only <font color=\"red\">possible dependencies are pairwise linear relationships</font>.\n",
    "        - Thus, in multivariate normal distributions, <font color=\"red\">uncorrelated random variables are statistically independent</font>\n",
    "    - The multivariate normal distribution has another important property.\n",
    "        - Then it is straightforward to show that the <font color=\"red\">decision boundary</font> that maximizes accuracy is always linear or quadratic\n",
    "        - The <font color=\"red\">optimal boundary</font> is <font color=\"red\">linear</font> if the two perceptual distributions have <font color=\"red\">equal</font> <font color=\"red\">variance-covariance matrices</font>\n",
    "        - the optimal boundary is <font color=\"red\">quadratic</font> if the two variance-covariance matrices are <font color=\"red\">unequal</font>.\n",
    "        - Thus, in the <font color=\"red\">Gaussian version of GRT</font>, the only decision bounds that are typically <font color=\"red\">considered are either linear or quadratic</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Bivariate normal distributions</font>, like those depicted in Figure 2.1 are each characterized by <font color=\"red\">five parameters</font>: \n",
    "    - a <font color=\"red\">mean</font> on each dimension, \n",
    "    - a <font color=\"red\">variance</font> on each dimension, and \n",
    "    - a <font color=\"red\">covariance or correlation</font> between the values on the two dimensions.\n",
    "* These are typically catalogued in \n",
    "    - a <font color=\"red\">mean vector</font> and \n",
    "    - a <font color=\"red\">variance-covariance matrix</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying GRT to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The entry in row i and column j lists the number of trials on which stimulus Si was presented and the subject gave response Rj . \n",
    "    - Thus, the entries on the main <font color=\"red\">diagonal</font> give the frequencies of all <font color=\"red\">correct responses</font> and \n",
    "    - the <font color=\"red\">off-diagonal</font> entries describe the various <font color=\"red\">errors</font> (or confusions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General recognition theory has been used to analyze data from confusion matrices in two different ways.\n",
    "    - One is to <font color=\"red\">fit the model to the entire confusion matrix</font>.\n",
    "    - The other method for using GRT to <font color=\"red\">test assumptions about perceptual processing</font>, which is arguably more popular, is to compute certain summary statistics from the empirical confusion matrix and then to check whether these satisfy certain conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fitting the GRT Model to Identification Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ESTIMATING THE PARAMETERS\n",
    "* EVALUATING GOODNESS OF FIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESTIMATING THE PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING GOODNESS OF FIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.2-1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.2-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Summary Statistics Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MACRO-ANALYSES\n",
    "* MICRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics approach draws inferences about \n",
    "    * perceptual independence,\n",
    "    * perceptual separability, and \n",
    "    * decisional separability \n",
    "    \n",
    "by using summary statistics that are easily computed from a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Macro-analyses draw conclusions about perceptual and decisional separability from changes in\n",
    "    - accuracy, \n",
    "    - sensitivity, and \n",
    "    - bias measures computed for one dimension across levels of a second dimension.\n",
    "* marginal response invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.19.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Marginal response invariance is closely related to perceptual and decisional separability.\n",
    "    - Fig 2.3,\n",
    "        - Dimension X 1 is decisionally but not perceptually separable from dimension X 2;\n",
    "        - the distance between the means of the perceptual distributions along- the X 1 axis is much greater for the top two stimuli than for the bottom two stimuli. \n",
    "        - The marginal distributions at the bottom of Figure 2.3 show that the proportion of correct responses, represented by the light-grey areas under the curves, is larger in the second level of X 2 than in the first level. \n",
    "            - The result would be similar if perceptual separability held and decisional separability failed, as would be the case for X2 if its decision bound was not perpendicular to its main axis.\n",
    "    - To test marginal response invariance in dimension X 1, \n",
    "        - we estimate the various probabilities in Eq. 18 from the empirical confusion matrix that results from this identification experiment. \n",
    "        - Next, equality between the two sides of Eq. 18 is assessed via a standard statistical test.\n",
    "        - These computations are repeated for both levels of component A and if either of the two tests is significant, \n",
    "        - then we conclude that marginal response invariance fails,\n",
    "        - and, therefore, that either perceptual or decisional separability are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* identification hit rate\n",
    "    - The left side of Eq. 18 equals P(ai |AiB1) and the right side equals P(ai|AiB2). \n",
    "    - These are the probabilities that component Ai is correctly identified and are analogous to “hit” rates in signal detection theory. \n",
    "    - To emphasize this relationship, we define the identification hit rate of component Ai on trials when stimulus AiBj is presented as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* false alarm rates\n",
    "    - In Figure 2.3, note that the dark grey areas in the marginal distributions equal Fa1|A2B2 (top) and Fa1|A2B1 (bottom). \n",
    "    - In signal detection theory,\n",
    "        - hit and false-alarm rates are used to measure <font color=\"red\">stimulus discriminability</font>.\n",
    "        - We can use the identification analogues to compute <font color=\"red\">marginal discriminabilities</font> for each stimulus component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The equality between two d`s can be tested using the following statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* marginal response criterion\n",
    "    - Marginal hit and false-alarm rates can also be used to compute a marginal response criterion.\n",
    "    - Several measures of response criterion and bias have been proposed (see Chapter 2 of Macmillan & Creelman, 2005), but perhaps the most widely used criterion measure in recent years (due to Kadlec, 1999) is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.25.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.26.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.27.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.28.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# An Empirical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extensions to Response Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The RT-Distance Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.29.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Process Models of RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Implementations of GRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] The Oxford Handbook of Computational and Mathematical Psychology - http://www.amazon.com/Handbook-Computational-Mathematical-Psychology-Library/dp/0199957991\n",
    "* [2]신호탐지이론 (한글위키백과) - http://ko.wikipedia.org/wiki/%EC%8B%A0%ED%98%B8%ED%83%90%EC%A7%80%EC%9D%B4%EB%A1%A0\n",
    "* [3]Detection_theory (wikipedia) -  http://en.wikipedia.org/wiki/Detection_theory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
