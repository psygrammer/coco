{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Multidimensional Signal Detection Theory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 인지모델링 스터디 교재 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Abstract\n",
    "* Introduction\n",
    "* General Recognition Theory\n",
    "* The Multivariate Normal Model\n",
    "* Applying GRT to Data\n",
    "* Fitting the GRT Model to Identification Data\n",
    "* The Summary Statistics Approach\n",
    "* An Empirical Example\n",
    "* Extensions to Response Time\n",
    "* The RT-Distance Hypothesis\n",
    "* Process Models of RT\n",
    "* Neural Implementations of GRT\n",
    "* Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multidimensional signal detection theory\n",
    "    - <font color=\"red\">multivariate extension</font> of signal detection theory\n",
    "* two fundamental assumptions,\n",
    "    - every <font color=\"red\">mental state is noisy</font> \n",
    "    - every <font color=\"red\">action requires a decision</font>\n",
    "* The most widely studied version is known as <font color=\"red\">general recognition theory (GRT)</font>. \n",
    "    - General recognition theory assumes\n",
    "        - the <font color=\"red\">percept on each trial</font> can be <font color=\"red\">modeled as a random sample</font> from a <font color=\"red\">multivariate probability distribution</font> defined over the <font color=\"red\">perceptual space</font>.\n",
    "        - <font color=\"red\">Decision bounds divide</font> this space into <font color=\"red\">regions</font> that are each <font color=\"red\">associated with a response alternative</font>. \n",
    "* General recognition theory rigorously defines and tests \n",
    "    - a number of important <font color=\"red\">perceptual and cognitive conditions</font>, \n",
    "    - including <font color=\"red\">perceptual and decisional separability</font> \n",
    "    - and <font color=\"red\">perceptual independence</font>. \n",
    "* General recognition theory has been used to analyze data from identification experiments in two ways: \n",
    "    - (1) <font color=\"red\">fitting and comparing models</font> that make different assumptions about perceptual and decisional processing, \n",
    "    - (2) <font color=\"red\">testing assumptions</font> by computing summary statistics and checking whether these satisfy certain conditions. \n",
    "* Much has been learned recently about the neural networks that mediate the perceptual and decisional processing modeled by GRT, and this knowledge can be used to improve the design of experiments where a GRT analysis is anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* signal detection theory\n",
    "* general recognition theory\n",
    "* perceptual separability\n",
    "* perceptual independence\n",
    "* identification\n",
    "* categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal detection theory(신호탐지이론) ? [2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://ko.wikipedia.org/wiki/%EC%8B%A0%ED%98%B8%ED%83%90%EC%A7%80%EC%9D%B4%EB%A1%A0\n",
    "* http://en.wikipedia.org/wiki/Detection_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/6/65/SignalDetection.png/600px-SignalDetection.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|         |         반응 \"없음\"            |        반응 \"있음\"\n",
    "| --------| ---------------------------- | -----------------------------\n",
    "| 신호 있음 | <font color=\"red\">누락</font>  |            적중\n",
    "| 신호 없음 |\t       정기각                | <font color=\"red\">오경보</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                  |          Respond  \"Absent\"           |        Respond \"Present\"\n",
    "| -----------------| ------------------------------------ | ------------------------------------\n",
    "| Stimulus Present |\t <font color=\"red\"> Miss</font>   |\t                 Hit\n",
    "| Stimulus Absent  |             Correct Rejection        |\t<font color=\"red\">False Alarm</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one sensory dimension signal detection theory \n",
    "* -> Multidimensional signal detection theory \n",
    "* -> (The most widely studied version of multidimensional signal detection theory is known as) general recognition theory\n",
    "    - First, with more than one dimension, it becomes necessary to model <font color=\"red\">interactions (or the lack thereof) among those dimensions</font>.\n",
    "    - Second, the problem of how to model decision processes when the perceptual space is multidimensional is <font color=\"red\">far more difficult than</font> when there is only one sensory dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# General Recognition Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As an example, \n",
    "\n",
    "* consider an experiment in which participants are asked to <font color=\"red\">categorize or identify faces</font> that vary across trials on <font color=\"red\">gender and age</font>.\n",
    "* Suppose there are <font color=\"red\">four stimuli (i.e., faces)</font> that are created by factorially <font color=\"red\">combining two levels of each dimension</font>. \n",
    "* In this case we could denote \n",
    "    - the <font color=\"red\">two levels of the gender dimension</font> by \n",
    "        - A1 (male) and\n",
    "        - A2 (female) \n",
    "    - and the <font color=\"red\">two levels of the age dimension</font> by \n",
    "        - B1 (teen) and\n",
    "        - B2 (adult). \n",
    "* Then the four faces are denoted as \n",
    "    - A1B1 (male teen), \n",
    "    - A1B2 (male adult), \n",
    "    - A2B1 (female teen), and \n",
    "    - A2B2 (female adult)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with signal detection theory, a fundamental assumption of GRT is that <font color=\"red\">all perceptual systems are inherently noisy</font>. There is noise both in the <font color=\"red\">stimulus</font> (e.g., photon noise) and in the <font color=\"red\">neural systems</font> that determine its sensory representation (Ashby & Lee, 1993). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.1-1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.1-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perceptual separability\n",
    "#### perceptual independence\n",
    "#### decisional separability\n",
    "\n",
    "* In GRT, the <font color=\"red\">relationship of the joint pdf to the marginal pdfs plays a critical role</font> in determining whether the stimulus dimensions are <font color=\"red\">perceptually integral</font> or <font color=\"red\">separable</font>.\n",
    "* Component A is <font color=\"red\">perceptually separable</font> from component B if the <font color=\"red\">subject’s perception of A does not change when the level of B is varied</font>.\n",
    "    - For example, age is perceptually separable from gender if the perceived age of the adult in our face experiment is the same for the male adult as for the female adult, and if a similar invariance holds for the perceived age of the teen.\n",
    "*  If perceptual separability fails then A and B are said to be <font color=\"red\">perceptually integral</font>.\n",
    "* Another purely perceptual phenomenon is <font color=\"red\">perceptual independence</font>.\n",
    "    - According to GRT, components A and B are perceived independently in stimulus AiBj if and only if the perceptual value of component A is statistically independent of the perceptual value of component B on AiBj trials.\n",
    "* Note that perceptual independence is a property of a single stimulus, whereas perceptual separability is a property of groups of stimuli.\n",
    "* A third important construct from GRT is decisional separability.\n",
    "    - In our hypothetical experiment with stimuli A1B1, A1B2, A2B1, and A2 B2, and two perceptual dimensions X1 and X 2, decisional separability holds on dimension X 1 (for example),\n",
    "    - if the subject’s decision about whether stimulus component A is at level 1 or 2 depends only on the perceived value on dimension X 1. \n",
    "    - A decision bound is a line or curve that separates regions of the perceptual space that elicit different responses. \n",
    "    - The only types of decision bounds that satisfy decisional separability are vertical and horizontal lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A is perceptually separable from B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B is perceptually separable from A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A and B are perceived independently in stimulus AiBj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Multivariate Normal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far we have made <font color=\"red\">no assumptions about the form of the joint or marginal pdfs</font>. \n",
    "* Our <font color=\"red\">only assumption</font> has been that there exists some <font color=\"red\">probability distribution associated with each stimulus</font> and that these distributions are all embedded in some Euclidean space\n",
    "    - <font color=\"red\">the percepts are multivariate normally distributed</font>.\n",
    "    - The multivariate normal distribution includes two assumptions.\n",
    "        - First, the <font color=\"red\">marginal distributions are all normal</font>.\n",
    "        - Second, the only <font color=\"red\">possible dependencies are pairwise linear relationships</font>.\n",
    "        - Thus, in multivariate normal distributions, <font color=\"red\">uncorrelated random variables are statistically independent</font>\n",
    "    - The multivariate normal distribution has another important property.\n",
    "        - Then it is straightforward to show that the <font color=\"red\">decision boundary</font> that maximizes accuracy is always linear or quadratic\n",
    "        - The <font color=\"red\">optimal boundary</font> is <font color=\"red\">linear</font> if the two perceptual distributions have <font color=\"red\">equal</font> <font color=\"red\">variance-covariance matrices</font>\n",
    "        - the optimal boundary is <font color=\"red\">quadratic</font> if the two variance-covariance matrices are <font color=\"red\">unequal</font>.\n",
    "        - Thus, in the <font color=\"red\">Gaussian version of GRT</font>, the only decision bounds that are typically <font color=\"red\">considered are either linear or quadratic</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Bivariate normal distributions</font>, like those depicted in Figure 2.1 are each characterized by <font color=\"red\">five parameters</font>: \n",
    "    - a <font color=\"red\">mean</font> on each dimension, \n",
    "    - a <font color=\"red\">variance</font> on each dimension, and \n",
    "    - a <font color=\"red\">covariance or correlation</font> between the values on the two dimensions.\n",
    "* These are typically catalogued in \n",
    "    - a <font color=\"red\">mean vector</font> and \n",
    "    - a <font color=\"red\">variance-covariance matrix</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying GRT to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The entry in row i and column j lists the number of trials on which stimulus Si was presented and the subject gave response Rj . \n",
    "    - Thus, the entries on the main <font color=\"red\">diagonal</font> give the frequencies of all <font color=\"red\">correct responses</font> and \n",
    "    - the <font color=\"red\">off-diagonal</font> entries describe the various <font color=\"red\">errors</font> (or confusions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General recognition theory has been used to analyze data from confusion matrices in two different ways.\n",
    "    - One is to <font color=\"red\">fit the model to the entire confusion matrix</font>.\n",
    "    - The other method for using GRT to <font color=\"red\">test assumptions about perceptual processing</font>, which is arguably more popular, is to compute certain summary statistics from the empirical confusion matrix and then to check whether these satisfy certain conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fitting the GRT Model to Identification Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ESTIMATING THE PARAMETERS\n",
    "* EVALUATING GOODNESS OF FIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESTIMATING THE PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING GOODNESS OF FIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.2-1.PNG\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/box2.2-2.PNG\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Summary Statistics Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MACRO-ANALYSES\n",
    "* MICRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics approach draws inferences about \n",
    "    * perceptual independence,\n",
    "    * perceptual separability, and \n",
    "    * decisional separability \n",
    "    \n",
    "by using summary statistics that are easily computed from a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Macro-analyses draw conclusions about perceptual and decisional separability from changes in\n",
    "    - accuracy, \n",
    "    - sensitivity, and \n",
    "    - bias measures computed for one dimension across levels of a second dimension.\n",
    "* marginal response invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.19.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Marginal response invariance is closely related to perceptual and decisional separability.\n",
    "    - Fig 2.3,\n",
    "        - Dimension X 1 is decisionally but not perceptually separable from dimension X 2;\n",
    "        - the distance between the means of the perceptual distributions along- the X 1 axis is much greater for the top two stimuli than for the bottom two stimuli. \n",
    "        - The marginal distributions at the bottom of Figure 2.3 show that the proportion of correct responses, represented by the light-grey areas under the curves, is larger in the second level of X 2 than in the first level. \n",
    "            - The result would be similar if perceptual separability held and decisional separability failed, as would be the case for X2 if its decision bound was not perpendicular to its main axis.\n",
    "    - To test marginal response invariance in dimension X 1, \n",
    "        - we estimate the various probabilities in Eq. 18 from the empirical confusion matrix that results from this identification experiment. \n",
    "        - Next, equality between the two sides of Eq. 18 is assessed via a standard statistical test.\n",
    "        - These computations are repeated for both levels of component A and if either of the two tests is significant, \n",
    "        - then we conclude that marginal response invariance fails,\n",
    "        - and, therefore, that either perceptual or decisional separability are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* identification hit rate\n",
    "    - The left side of Eq. 18 equals P(ai |AiB1) and the right side equals P(ai|AiB2). \n",
    "    - These are the probabilities that component Ai is correctly identified and are analogous to “hit” rates in signal detection theory. \n",
    "    - To emphasize this relationship, we define the identification hit rate of component Ai on trials when stimulus AiBj is presented as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* false alarm rates\n",
    "    - In Figure 2.3, note that the dark grey areas in the marginal distributions equal Fa1|A2B2 (top) and Fa1|A2B1 (bottom). \n",
    "    - In signal detection theory,\n",
    "        - hit and false-alarm rates are used to measure <font color=\"red\">stimulus discriminability</font>.\n",
    "        - We can use the identification analogues to compute <font color=\"red\">marginal discriminabilities</font> for each stimulus component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The equality between two d`s can be tested using the following statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* marginal response criterion\n",
    "    - Marginal hit and false-alarm rates can also be used to compute a marginal response criterion.\n",
    "    - Several measures of response criterion and bias have been proposed (see Chapter 2 of Macmillan & Creelman, 2005), but perhaps the most widely used criterion measure in recent years (due to Kadlec, 1999) is (25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As shown in Figure 2.3, this measure represents the placement of the decision-bound relative to the center of the A2Bj distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.25.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To test the difference between two c values, the following test statistic can be used (Kadlec, 1999):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.26.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.27.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICRO-ANALYSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Macro-analyses focus on properties of the entire stimulus ensemble. \n",
    "* In contrast, micro-analyses test assumptions about perceptual independence and decisional separability by examining summary statistics computed for <font color=\"red\">only one or two stimuli</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sampling independence\n",
    "    - The most widely used test of perceptual independence is via sampling independence, which holds when the probability of reporting a combination of components P(aibj ) equals the product of the probabilities of reporting each component alone, P(ai)P(bj ).\n",
    "    - For example, sampling independence holds for stimulus A1B1 if and only if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.28.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sampling independence provides a strong test of perceptual independence if decisional separability holds. \n",
    "* In fact, if decisional separability holds on both dimensions, then sampling independence holds if and only if perceptual independence holds (Ashby & Townsend, 1986)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">sampling independence</font>\n",
    "    - Figure 2.4A gives an intuitive illustration of this theoretical result. \n",
    "        -  Two cases are presented in which decisional separability holds on both dimensions and the decision bounds cross at the mean of the perceptual distribution. \n",
    "        - In the distribution to the left, perceptual independence holds and it is easy to see that all four responses are equally likely. \n",
    "        - Thus, the volume of this bivariate normal distribution in response region R4 = a2b2 is 0.25. \n",
    "        - It is also easy to see that half of each marginal distribution lies above its relevant decision criterion (i.e., the two shaded regions), so P(a2) = P(b2) = 0.5. \n",
    "        - As a result, sampling independence is satisfied since P(a2b2) = P(a2) × P(b2)\n",
    "*  <font color=\"red\">discriminability and criterion measures</font>\n",
    "    - Perceptual independence can also be assessed through discriminability and criterion measures computed for one dimension conditioned on the perceived value on the other dimension.\n",
    "    - Figure 2.4B shows \n",
    "        - the perceptual distributions of two stimuli that share the same level of component B\n",
    "(i.e., B1) and have the same perceptual mean on dimension X 2.\n",
    "        - The decision bound perpendicular to X 2 separates the perceptual plane into two regions:\n",
    "            - percepts falling in the upper region elicit an incorrect response on component B (i.e., a miss for B), \n",
    "            - whereas percepts falling in the lower region elicit a correct B response (i.e., a hit). The bottom of the figure shows the marginal distribution for each stimulus conditioned on whether B is a hit or a miss. When perceptual independence holds,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that if perceptual independence and decisional separability both hold, then the tests based on <font color=\"red\">sampling independence</font> and <font color=\"red\">equal conditional d` and c</font> should lead to the same conclusion. \n",
    "    -  Conditional d` and c values can be computed from hit and false alarm rates for two stimuli differing in one dimension, conditioned on the reported level of the second dimension.\n",
    "* If only one of these two tests holds and the other fails, this indicates a <font color=\"red\">violation of decisional separability</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# An Empirical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we show with a concrete example how to analyze the data from an identification experiment using GRT.\n",
    "    - We will first analyze the data by fitting GRT models to the identification confusion matrix,\n",
    "    - -> and then we will conduct summary statistics analyses on the same data.\n",
    "    - -> Finally, we will compare the results from the two separate analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imagine that you are a researcher interested in how the age and gender of faces interact during face recognition.\n",
    "    - You run an experiment in which subjects must identify four stimuli\n",
    "    - the combination of two levels of age (teen and adult) and\n",
    "    - two levels of gender (male and female).\n",
    "    - Each stimulus is presented 250 times, for a total of 1,000 trials in the whole experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data to be analyzed are summarized in the confusion matrix displayed in Table 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">These data were generated by random sampling from the model</font> shown in Figure 2.5A.\n",
    "    - The advantage of <font color=\"red\">generating artificial data from this model</font> is that we know in advance what conclusions should be reached by our analyses. \n",
    "    - For example, note that <font color=\"red\">decisional separability holds</font> in the Figure 2.5A model.\n",
    "    - Also, because the distance between the “male” and “female” distributions is larger for “adult” than for “teen,” <font color=\"red\">gender is not perceptually separable from age</font>. \n",
    "    - In contrast, the “adult” and “teen” marginal distributions are the same across levels of gender, so <font color=\"red\">age is perceptually separable from gender</font>. \n",
    "    - Finally, because all distributions <font color=\"red\">show a positive correlation</font>, <font color=\"red\">perceptual independence is violated</font> for all stimuli.\n",
    "    * A <font color=\"red\">hierarchy of models were fit</font> to the data in Table 2.1 <font color=\"red\">using maximum likelihood estimation</font>. \n",
    "    - Figure 2.5C shows the hierarchy of models used for the analysis, \n",
    "        - together with the number of <font color=\"red\">free parameters m</font> for each of them. \n",
    "        - In this figure, \n",
    "            - <font color=\"red\">PS</font> stands for perceptual separability, \n",
    "            - <font color=\"red\">PI</font> for perceptual independence, \n",
    "            - <font color=\"red\">DS</font> for decisional separability and \n",
    "            - <font color=\"red\">1_RHO</font> describes a model with a single correlation parameter for all distributions. \n",
    "            - Note that several other models could be tested, depending on specific research goals and hypotheses, or on the results from <font color=\"red\">summary statistics analysis</font>.\n",
    "        - <font color=\"red\">The arrows</font> in Figure 2.5C connect models that are <font color=\"red\">nested within each other</font>. \n",
    "            - The result of likelihood ratio tests comparing such \n",
    "                - nested models are displayed next to each arrow, \n",
    "                - with an <font color=\"red\">asterisk</font> representing significantly better fit for the more general model (lower in the hierarchy) and \n",
    "                - <font color=\"red\">n.s.</font> representing a nonsignificant difference in fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl2.2-4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extensions to Response Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The RT-Distance Hypothesis\n",
    "* Process Models of RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There have been a number of <font color=\"red\">extensions of GRT</font> that allow the theory to account both for <font color=\"red\">response accuracy</font> and <font color=\"red\">response time (RT)</font>.\n",
    "    - One approach was to <font color=\"red\">add the fewest and least controversial assumptions</font> possible that would allow GRT to make RT predictions.\n",
    "        - The resulting model succeeds, <font color=\"red\">but it offers no process interpretation</font> of how a decision is reached on each trial. \n",
    "    - An alternative approach is to <font color=\"red\">add enough theoretical structure</font> to make RT predictions and to describe the perceptual and cognitive processes that generated that decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The RT-Distance Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In standard univariate signal detection theory, the <font color=\"red\">most common RT assumption</font> is that RT decreases with the distance between the perceptual effect and the response criterion.\n",
    "* The obvious multivariate analog of this, which is known as the <font color=\"red\">RT-distance hypothesis</font>, assumes that <font color=\"red\">RT decreases with the distance between the percept and the decision bound</font>.\n",
    "* <font color=\"red\">Efforts to incorporate the RT-distance hypothesis into GRT</font> have been limited to <font color=\"red\">two-choice experimental paradigms</font>, such as \n",
    "    - <font color=\"red\">categorization</font> or \n",
    "    - <font color=\"red\">speeded classification</font>, which can be modeled with a single decision bound.\n",
    "* The most general form of the RT-distance hypothesis makes <font color=\"red\">no assumptions about the parametric form</font> of the function that relates RT and distance to bound. \n",
    "* The<font color=\"red\"> only assumption</font> is that this <font color=\"red\">function is monotonically decreasing</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For example, consider a <font color=\"red\">filtering task</font> \n",
    "    - with stimuli A1B1, A1B2, A2B1, and A2 B2,\n",
    "    -  and two perceptual dimensions X1 and X2, \n",
    "    - in which the subject’s task on each trial is to name the level of component A.\n",
    "    - Let PFA(RTi < t|AiBj ) denote the probability that \n",
    "        - the RT is less than or equal to some value t on trials of a filtering task \n",
    "        - when the subject correctly classified the level of component A. \n",
    "        - Given this, then the RT analog of marginal response invariance, referred to as <font color=\"red\">marginal RT invariance</font>, can be defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.29.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ashby and Maddox (1994) showed that perceptual separability holds if and only if marginal RT invariance holds for both correct and incorrect responses.\n",
    "* Note that this is an if and only if result, which was not true for marginal response invariance.\n",
    "* In particular, if decisional separability and marginal response invariance both hold, perceptual separability could still be violated. \n",
    "* But if decisional separability, marginal RT invariance, and the RT-distance hypothesis all hold, then perceptual separability must be satisfied. \n",
    "* The reason we get the stronger result with RTs is that marginal RT invariance requires that Eq. 29 holds for all values of t, whereas marginal response invariance only requires a single equality to hold. \n",
    "* A similar strong result could be obtained with accuracy data if marginal response invariance were required to hold for all possible placements of the response criterion (i.e., the point where the vertical decision bound intersects the X 1 axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Process Models of RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At least three different process models have been proposed that account for both RT and accuracy within a GRT framework.\n",
    "    - Ashby (1989) proposed a stochastic interpretation of GRT that was instantiated in a discrete-time linear system.\n",
    "    - Townsend, Houpt, and Silbert (2012) considerably generalized the stochastic model proposed by Ashby (1989) by extending it to a broad class of parallel processing models. \n",
    "    - Ashby (2000) took a different approach. Rather than specify a processing architecture, he proposed that moment-by-moment fluctuations in the percept could be modeled via a continuous-time multivariate diffusion process.\n",
    "        - This stochastic version of GRT is more biologically plausible than the Ashby (1989) version (e.g., see Smith & Ratcliff, 2004) and it <font color=\"red\">establishes links</font> to the voluminous work on <font color=\"red\">diffusion models of decision making</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Implementations of GRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Of course, the perceptual and cognitive processes modeled by GRT are mediated by circuits in the brain.\n",
    "* During the past decade or two, much has been learned about the architecture and functioning of these circuits. Perhaps most importantly, there is now overwhelming evidence that <font color=\"red\">humans have multiple neuroanatomically and functionally distinct learning systems</font>.\n",
    "    - The most complete  escription of two of the most important learning systems is arguably provided by the COVIS theory of category learning (Ashby, Alfonso-Reese, Turken, & Waldron, 1998; Ashby, Paul, & Maddox, 2011).\n",
    "        - <font color=\"red\">COVIS</font> assumes separate \n",
    "            - <font color=\"red\">rule-based</font> and \n",
    "            - <font color=\"red\">procedural-learning</font> categorization systems that compete for access to response production.\n",
    "            - The rule-based system uses executive attention and working memory to select and test simple verbalizable hypotheses about category membership.\n",
    "            - The procedural system gradually associates categorization responses with regions of perceptual space via reinforcement learning.\n",
    "            - COVIS assumes that rule-based categorization is mediated by a broad neural network that includes the prefrontal cortex, anterior cingulate, head of the caudate nucleus, and the hippocampus, whereas the key structures in the procedural-learning system are the striatum and the premotor cortex. \n",
    "            - Virtually all decision rules that satisfy decisional separability are easily verbalized. \n",
    "            - In fact, COVIS assumes that the rule-based system is constrained to use rules that satisfy decisional separability (at least piecewise). \n",
    "            - In contrast, the COVIS procedural system has no such constraints. Instead, it tends to learn decision strategies that approximate the optimal bound.\n",
    "* As we have consistently seen throughout this chapter, <font color=\"red\">decisional separability greatly simplifies</font> applications of GRT to behavioral data. Thus, researchers who want to increase the probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multidimensional signal detection theory in general, and GRT in particular, make two fundamental assumptions, namely that every mental state is noisy and that every action requires a decision.\n",
    "* Multidimensional signal detection theory captures two fundamental features of almost all behaviors. \n",
    "* Beyond these two assumptions, however, the theory is flexible enough to model a wide variety of decision processes and sensory and perceptual interactions.\n",
    "* For these reasons, the popularity of multidimensional signal detection theory is likely to grow in the coming decades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fsotoc/grtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"devtools\")\n",
    "#devtools::install_github(\"fsotoc/grtools\", dependencies=\"Imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(grtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for grtools-package {grtools}\"><tr><td>grtools-package {grtools}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>\n",
       "General recognition theory tools for the analysis of perceptual independence\n",
       "</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Statistical tools from General Recognition Theory for psychophysical data analyses aimed at determining independent processing of perceptual dimensions\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "\n",
       "<table summary=\"Rd table\">\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "Package: </td><td style=\"text-align: left;\"> grtools</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "Type: </td><td style=\"text-align: left;\"> Package</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "Version: </td><td style=\"text-align: left;\"> 0.1.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "Date: </td><td style=\"text-align: left;\"> 2015-03-26</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "License: </td><td style=\"text-align: left;\"> GPL (&gt;= 2)</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "</td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "<p><code>grtools</code> provides functions for the following analyses using general recognition theory:\n",
       "</p>\n",
       "<p>1. Model-based analyses of separability and independence with GRT-wIND for the 2x2 identification experiment (Soto et al., 2015). See <code>grt_wind_fit</code> and <code>grt_wind_fit_parallel</code>\n",
       "</p>\n",
       "<p>2. Model-based analyses of separability and independence with traditional GRT models for the 2x2 identification experiment (Ashby &amp; Soto, 2015). See <code>grt_hm_fit</code>\n",
       "</p>\n",
       "<p>3. Summary statistics analysis (i.e. Kadlec's MDSDA; see Kadlec &amp; Townsend, 1992) for the 2x2 identification experiment. See <code>sumstats_micro</code> and <code>sumstats_macro</code>\n",
       "</p>\n",
       "<p>4. Summary statistic analysis for the 2x2 Garner filtering task (Ashby &amp; Maddox, 1994). See <code>sumstats_garner</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Fabian Soto, Emily Zheng\n",
       "</p>\n",
       "<p>Maintainer: Fabian Soto &lt;fabian.soto@psych.ucsb.edu&gt;\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Ashby, F. G., &amp; Soto, F. A. (2015). Multidimensional signal detection theory. In J. R. Busemeyer, J. T. Townsend, Z. J. Wang, &amp; A. Eidels (Eds.), <em>Oxford handbook of computational and mathematical psychology</em> (pp. 13-34). Oxford University Press: New York, NY.\n",
       "</p>\n",
       "<p>Ashby, F. G., &amp; Maddox, W. T. (1994). A response time theory of separability and integrality in speeded classification. <em>Journal of Mathematical Psychology, 38</em>(4), 423-466.\n",
       "</p>\n",
       "<p>Kadlec, H., &amp; Townsend, J. T. (1992). Signal detection analyses of multidimensional interactions. In F. G. Ashby (Ed.), <em>Multidimensional models of perception and cognition</em> (pp. 181–231). Hillsdale, NJ: Erlbaum.\n",
       "</p>\n",
       "<p>Soto, F. A., Musgrave, R., Vucovich, L., &amp; Ashby, F. G. (2015). General recognition theory with individual differences: A new method for examining perceptual and decisional interactions with an application to face perception. <em>Psychonomic Bulletin &amp; Review, 22</em>(1), 88-111.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>For applications of General Recognition Theory to perceptual categorization experiments, see <code><a href=\"http://cran.r-project.org/web/packages/grt/index.html\">grt</a>\n",
       "</code>\n",
       "</p>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>grtools</em> version 0.1.2 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{grtools-package}{General recognition theory tools for the analysis of perceptual independence}{grtools.Rdash.package}\n",
       "\\aliasA{grtools}{grtools-package}{grtools}\n",
       "\\keyword{package, general recognition theory, grt, mdsdt, signal detection theory,}{grtools-package}\n",
       "\\keyword{perceptual separability, perceptual independence, separability}{grtools-package}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Statistical tools from General Recognition Theory for psychophysical data analyses aimed at determining independent processing of perceptual dimensions\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "\n",
       "\\Tabular{ll}{\n",
       "Package: & grtools\\\\{}\n",
       "Type: & Package\\\\{}\n",
       "Version: & 0.1.2\\\\{}\n",
       "Date: & 2015-03-26\\\\{}\n",
       "License: & GPL (>= 2)\\\\{}\n",
       "}\n",
       "\\code{grtools} provides functions for the following analyses using general recognition theory:\n",
       "\n",
       "1. Model-based analyses of separability and independence with GRT-wIND for the 2x2 identification experiment (Soto et al., 2015). See \\code{\\LinkA{grt\\_wind\\_fit}{grt.Rul.wind.Rul.fit}} and \\code{\\LinkA{grt\\_wind\\_fit\\_parallel}{grt.Rul.wind.Rul.fit.Rul.parallel}}\n",
       "\n",
       "2. Model-based analyses of separability and independence with traditional GRT models for the 2x2 identification experiment (Ashby \\& Soto, 2015). See \\code{\\LinkA{grt\\_hm\\_fit}{grt.Rul.hm.Rul.fit}}\n",
       "\n",
       "3. Summary statistics analysis (i.e. Kadlec's MDSDA; see Kadlec \\& Townsend, 1992) for the 2x2 identification experiment. See \\code{\\LinkA{sumstats\\_micro}{sumstats.Rul.micro}} and \\code{\\LinkA{sumstats\\_macro}{sumstats.Rul.macro}}\n",
       "\n",
       "4. Summary statistic analysis for the 2x2 Garner filtering task (Ashby \\& Maddox, 1994). See \\code{\\LinkA{sumstats\\_garner}{sumstats.Rul.garner}}\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Fabian Soto, Emily Zheng\n",
       "\n",
       "Maintainer: Fabian Soto <fabian.soto@psych.ucsb.edu>\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Ashby, F. G., \\& Soto, F. A. (2015). Multidimensional signal detection theory. In J. R. Busemeyer, J. T. Townsend, Z. J. Wang, \\& A. Eidels (Eds.), \\emph{Oxford handbook of computational and mathematical psychology} (pp. 13-34). Oxford University Press: New York, NY.\n",
       "\n",
       "Ashby, F. G., \\& Maddox, W. T. (1994). A response time theory of separability and integrality in speeded classification. \\emph{Journal of Mathematical Psychology, 38}(4), 423-466.\n",
       "\n",
       "Kadlec, H., \\& Townsend, J. T. (1992). Signal detection analyses of multidimensional interactions. In F. G. Ashby (Ed.), \\emph{Multidimensional models of perception and cognition} (pp. 181–231). Hillsdale, NJ: Erlbaum.\n",
       "\n",
       "Soto, F. A., Musgrave, R., Vucovich, L., \\& Ashby, F. G. (2015). General recognition theory with individual differences: A new method for examining perceptual and decisional interactions with an application to face perception. \\emph{Psychonomic Bulletin \\& Review, 22}(1), 88-111.\n",
       "\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "For applications of General Recognition Theory to perceptual categorization experiments, see \\code{\\Rhref{http://cran.r-project.org/web/packages/grt/index.html}{grt}\n",
       "}\n",
       "\\end{SeeAlso}"
      ],
      "text/plain": [
       "grtools-package            package:grtools             R Documentation\n",
       "\n",
       "_\bG_\be_\bn_\be_\br_\ba_\bl _\br_\be_\bc_\bo_\bg_\bn_\bi_\bt_\bi_\bo_\bn _\bt_\bh_\be_\bo_\br_\by _\bt_\bo_\bo_\bl_\bs _\bf_\bo_\br _\bt_\bh_\be _\ba_\bn_\ba_\bl_\by_\bs_\bi_\bs _\bo_\bf _\bp_\be_\br_\bc_\be_\bp_\bt_\bu_\ba_\bl\n",
       "_\bi_\bn_\bd_\be_\bp_\be_\bn_\bd_\be_\bn_\bc_\be\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Statistical tools from General Recognition Theory for\n",
       "     psychophysical data analyses aimed at determining independent\n",
       "     processing of perceptual dimensions\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "       Package:  grtools    \n",
       "       Type:     Package    \n",
       "       Version:  0.1.2      \n",
       "       Date:     2015-03-26 \n",
       "       License:  GPL (>= 2) \n",
       "      \n",
       "     ‘grtools’ provides functions for the following analyses using\n",
       "     general recognition theory:\n",
       "\n",
       "     1. Model-based analyses of separability and independence with\n",
       "     GRT-wIND for the 2x2 identification experiment (Soto et al.,\n",
       "     2015). See ‘grt_wind_fit’ and ‘grt_wind_fit_parallel’\n",
       "\n",
       "     2. Model-based analyses of separability and independence with\n",
       "     traditional GRT models for the 2x2 identification experiment\n",
       "     (Ashby & Soto, 2015). See ‘grt_hm_fit’\n",
       "\n",
       "     3. Summary statistics analysis (i.e. Kadlec's MDSDA; see Kadlec &\n",
       "     Townsend, 1992) for the 2x2 identification experiment. See\n",
       "     ‘sumstats_micro’ and ‘sumstats_macro’\n",
       "\n",
       "     4. Summary statistic analysis for the 2x2 Garner filtering task\n",
       "     (Ashby & Maddox, 1994). See ‘sumstats_garner’\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Fabian Soto, Emily Zheng\n",
       "\n",
       "     Maintainer: Fabian Soto <fabian.soto@psych.ucsb.edu>\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Ashby, F. G., & Soto, F. A. (2015). Multidimensional signal\n",
       "     detection theory. In J. R. Busemeyer, J. T. Townsend, Z. J. Wang,\n",
       "     & A. Eidels (Eds.), _Oxford handbook of computational and\n",
       "     mathematical psychology_ (pp. 13-34). Oxford University Press: New\n",
       "     York, NY.\n",
       "\n",
       "     Ashby, F. G., & Maddox, W. T. (1994). A response time theory of\n",
       "     separability and integrality in speeded classification. _Journal\n",
       "     of Mathematical Psychology, 38_(4), 423-466.\n",
       "\n",
       "     Kadlec, H., & Townsend, J. T. (1992). Signal detection analyses of\n",
       "     multidimensional interactions. In F. G. Ashby (Ed.),\n",
       "     _Multidimensional models of perception and cognition_ (pp.\n",
       "     181–231). Hillsdale, NJ: Erlbaum.\n",
       "\n",
       "     Soto, F. A., Musgrave, R., Vucovich, L., & Ashby, F. G. (2015).\n",
       "     General recognition theory with individual differences: A new\n",
       "     method for examining perceptual and decisional interactions with\n",
       "     an application to face perception. _Psychonomic Bulletin & Review,\n",
       "     22_(1), 88-111.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     For applications of General Recognition Theory to perceptual\n",
       "     categorization experiments, see ‘grt ’\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?grtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] The Oxford Handbook of Computational and Mathematical Psychology - http://www.amazon.com/Handbook-Computational-Mathematical-Psychology-Library/dp/0199957991\n",
    "* [2]신호탐지이론 (한글위키백과) - http://ko.wikipedia.org/wiki/%EC%8B%A0%ED%98%B8%ED%83%90%EC%A7%80%EC%9D%B4%EB%A1%A0\n",
    "* [3]Detection_theory (wikipedia) -  http://en.wikipedia.org/wiki/Detection_theory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
